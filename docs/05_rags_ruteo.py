# -*- coding: utf-8 -*-
"""05 RAGs - Ruteo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-kpbGAGsxW0CsTvQWh6GxnMxAJYoeDvi

## Ruteo de consultas

## Entorno
"""

! pip install -qU langchain_huggingface
! pip install -qU langchain-chroma
! pip install -qU langchain-community
! pip install -qU langchain[google-genai]

import os

os.environ["GOOGLE_API_KEY"] = ""

from langchain.chat_models import init_chat_model

llm = init_chat_model("gemini-2.5-flash-lite", model_provider="google_genai")

"""## *Embeddings* locales"""

from langchain_huggingface import HuggingFaceEmbeddings

# embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")

# e = embeddings.embed_query("Hello world")
# print(f"{len(e)=}, {e=}")

# ed = embeddings.embed_documents(["Hello world", "This is an example"])
# print(f"{ed=}")

embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

e = embeddings.embed_query("Hello world")
print(f"{len(e)=}, {e=}")

ed = embeddings.embed_documents(["Hello world", "This is an example"])
print(f"{ed=}")

"""## RAG"""

from langchain_core.prompts import PromptTemplate
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chat_models import init_chat_model

class RAG():
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
        self.vector_store = Chroma(collection_name="curso_llm", embedding_function=self.embeddings, persist_directory="./chroma_langchain_db")
        self.llm = init_chat_model("gemini-2.5-flash", model_provider="google_genai")

    def index(self, documents):
        """Cargar los documentos, partirlos en fragmentos, calcular los embeddings e indexarlos."""
        self.documents = documents
        self.vector_store.reset_collection()
        self.vector_store.add_documents(self.documents)

    def retrieve_with_scores(self, query, k=3, filter=None):
        """Encontrar los k documentos más relevantes para una consulta dada. Retornar los documentos y los scores"""
        scores = self.vector_store.similarity_search_with_score(query, k=k, filter=filter)
        return scores

    def retrieve(self, query, k=3, filter=None):
        """Encontrar los k documentos más relevantes para una consulta dada. Retornar los documentos"""
        scores = self.retrieve_with_scores(query, k=k, filter=filter)
        return [s[0] for s in scores] # es s[0] porque scores es una lista de tuplas, con el score en s[1]

    def generate(self, query, relevant_documents):
        """Genera una respuesta para una consulta basándote en los documentos más relevantes."""
        prompt_template = PromptTemplate(
            input_variables=["query", "documents"],
            template = """
            Question: {query}

            Documents:
            {documents}
        """)
        documents = "\n\n".join(doc.page_content for doc in relevant_documents)

        prompt = prompt_template.format(query=query, documents=documents)
        ai_msg = self.llm.invoke([prompt])

        return ai_msg.content

    def answer(self, query):
        """Genera una respuesta para una consulta."""
        relevant_documents = self.retrieve(query)
        answer = self.generate(query, relevant_documents)

        return answer

from langchain_core.documents import Document

documents = [
    Document(page_content="Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity."),
    Document(page_content="Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes."),
    Document(page_content="Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics."),
    Document(page_content="Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'."),
    Document(page_content="Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine."),
    Document(page_content="Galileo Galilei made significant telescopic astronomical observations, including the phases of Venus, the four largest moons of Jupiter, and sunspots, which strongly supported the heliocentric model."),
    Document(page_content="Nikola Tesla was a brilliant inventor best known for his contributions to the design of the modern alternating current (AC) electricity supply system."),
    Document(page_content="Stephen Hawking was a theoretical physicist and cosmologist whose work included black hole research and popularizing science with books like A Brief History of Time."),
    Document(page_content="Rosalind Franklin was a chemist and X-ray crystallographer whose work was crucial to understanding the molecular structures of DNA, RNA, viruses, and coal."),
    Document(page_content="Archimedes was an ancient Greek mathematician, physicist, engineer, inventor, and astronomer who famously discovered the principle of the lever and the buoyancy principle."),
    Document(page_content="Louis Pasteur was a chemist and microbiologist renowned for his discoveries of the principles of vaccination, microbial fermentation, and pasteurization."),
    Document(page_content="Max Planck was a theoretical physicist whose work on quantum theory, for which he won the Nobel Prize in Physics in 1918, laid the foundation for modern physics."),
    Document(page_content="Dmitri Mendeleev is credited with formulating the Periodic Law and creating a published version of the Periodic Table of Elements, which organized the known chemical elements."),
    Document(page_content="Alan Turing was a mathematician, computer scientist, logician, crypotanalyst and philosopher, often considered the father of theoretical computer science and artificial intelligence."),
]

sample_queries = [
    "Who introduced the theory of relativity?",
    "Who was the first computer programmer?",
    "What did Isaac Newton contribute to science?",
    "Who won two Nobel Prizes for research on radioactivity?",
    "Who was the father of artificial intelligence?"
]

expected_responses = [
    "Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.",
    "Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.",
    "Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.",
    "Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.",
    "Alan Turing is often considered the father of artificial intelligence'."
]

rag = RAG()
rag.index(documents)

"""# Ruteo de consultas consultas

### Ruteo lógico
"""

from pydantic import BaseModel, Field
from langchain_core.prompts import PromptTemplate

class QuestionCategory(BaseModel):
    category: str = Field(description="Select the best category for answering a given question.", enun=["information", "support"])

question_category_prompt_template = PromptTemplate(
    input_variables=["question"],
    template="""<instructions>
    <role>You are an expert at routing a user question to the appropriate data source.</role>
    <task>
    Based on the given question, classify it as:
    * "information": if the question is asking for information about our products.
    * "support": if the question is asking for support of one of our products.

    <question>
    Question: {question}
    </question>
    </task>
    </instructions>""")


question = "The computer is broken, can you fix it?"
question = "What are the specs of the latest gaming computer?"
prompt = question_category_prompt_template.format(question=question)
output = llm.with_structured_output(QuestionCategory).invoke([prompt])
category = output.category

print(f"{question=}")
print(f"{category=}")

"""### Ruteo Semántico"""

from langchain.utils.math import cosine_similarity
from langchain_core.prompts import PromptTemplate

physics_template = """You are a very smart physics professor.
You are great at answering questions about physics in a concise and easy to understand manner.
When you don't know the answer to a question you admit that you don't know.

Here is a question:
{query}"""

math_template = """You are a very good mathematician. You are great at answering math questions.
You are so good because you are able to break down hard problems into their component parts,
answer the component parts, and then put them together to answer the broader question.

Here is a question:
{query}"""


#query = "What's a black hole?"
query = "What is a function?"
prompt_templates = [physics_template, math_template]
prompt_embeddings = rag.embeddings.embed_documents(prompt_templates)
query_embedding = rag.embeddings.embed_query(query)

# Compute similarity
similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]
most_similar_prompt = prompt_templates[similarity.argmax()]

print(f"{most_similar_prompt=}")